{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNFdaTCTYq4tNrNZklOCfk3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahraDehghanian97/DenseNet_Vs._ResNet/blob/master/DenseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWheA6CSj3ft"
      },
      "source": [
        "# **Mount google drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r3444wwj6Mr",
        "outputId": "fbabe007-518c-4fa7-ec7a-4102e0477dcc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTSvl-QYjyo3"
      },
      "source": [
        "# **prerequisit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3bPfRvshs1o"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.layers import  Flatten, Dense, Input, Dropout \n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqTjhr0Rj0RW"
      },
      "source": [
        "# **call back**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZmRtsodjztK"
      },
      "source": [
        "class EarlyStoppingCallback(keras.callbacks.Callback):\n",
        "  def __init__(self,patience=0):\n",
        "    super(EarlyStoppingCallback,self).__init__()\n",
        "    self.patience=patience\n",
        "    self.best=np.Inf\n",
        "    self.wait=0\n",
        "    self.stopped_epoch=0\n",
        "  def on_epoch_end(self,epoch,logs=None):\n",
        "    current_loss=logs.get(\"val_loss\")\n",
        "    if np.less(current_loss,self.best):\n",
        "      self.best=current_loss\n",
        "      self.wait=0\n",
        "      self.best_weights=self.model.get_weights()\n",
        "    else:\n",
        "      self.wait+=1\n",
        "      print(\"\\nwait mode, step: %d\"% self.wait)\n",
        "      if self.wait>=self.patience:\n",
        "        self.stopped_epoch=epoch\n",
        "        self.model.stop_training=True\n",
        "        self.model.set_weights(self.best_weights)\n",
        "        print(\"epoch: %d : early stopping.\"% self.stopped_epoch)\n",
        "        self.wait = 0\n",
        "      \n",
        "\n",
        "es_callback=EarlyStoppingCallback(patience=5)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjMMgNOLkSzX"
      },
      "source": [
        "# **Make dataset ready**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97QoNMEWkXoZ"
      },
      "source": [
        "def load_photos(type,dir_name):\n",
        "    photo_list =[]\n",
        "    y = []\n",
        "    for file_name in (glob.glob(dir_name+'/*')):\n",
        "        img = image.load_img(file_name, target_size=input_size)\n",
        "        img = np.array(img)\n",
        "        photo_list.append(img)\n",
        "        y.append(type)\n",
        "    return photo_list , y \n",
        "  \n",
        "    \n",
        "input_size = (250,250)\n",
        "input_shape = (250,250,3)\n",
        "dir_name_indoor = \"/content/drive/MyDrive/Colab Notebooks/indoor\"\n",
        "dir_name_outdoor = \"/content/drive/MyDrive/Colab Notebooks/outdoor\"\n",
        "X1 , y1= load_photos(0,dir_name_indoor) \n",
        "X2 , y2= load_photos(1,dir_name_outdoor) \n",
        "X1.extend(X2)\n",
        "y1.extend(y2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.1, random_state=42)\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1R7jCWK8lg2"
      },
      "source": [
        "# **DenseNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBRmXnpA8lhf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "9185587e-727b-466e-e7b0-4f0d860569d8"
      },
      "source": [
        "keras.backend.clear_session() \n",
        "\n",
        "base_model = keras.applications.DenseNet201(include_top=False, weights=\"imagenet\",  input_shape=input_shape)\n",
        "base_model.trainable  = False\n",
        "model_dense = Sequential()\n",
        "model_dense.add(base_model)\n",
        "model_dense.add(Flatten())\n",
        "model_dense.add(Dense(2500,activation='relu'))\n",
        "model_dense.add(Dropout(0.2))\n",
        "model_dense.add(Dense(1000,activation='relu'))\n",
        "model_dense.add(Dropout(0.1))\n",
        "model_dense.add(Dense(250,activation='relu'))\n",
        "model_dense.add(Dense(50,activation='relu'))\n",
        "model_dense.add(Dense(10,activation='relu'))\n",
        "model_dense.add(Dense(2))\n",
        "tf.keras.utils.plot_model(model_dense,show_shapes=True,expand_nested=True)\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQtHFjQm8lhn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e6159a-69f7-48df-8a20-62d72713f0e8"
      },
      "source": [
        "model_dense.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "tb_callback = keras.callbacks.TensorBoard(log_dir=\"./logs\",histogram_freq=1)\n",
        "model_dense.fit(X_train,y_train,epochs=1000,validation_split=0.2,callbacks=[es_callback,tb_callback])\n",
        "\n",
        "prediction_without_fine_tune_dense =np.argmax(model_dense.predict(X_test),axis=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer ModuleWrapper has arguments in `__init__` and therefore must override `get_config`.\n",
            "Epoch 1/1000\n",
            "18/18 [==============================] - 223s 12s/step - loss: 16.9779 - accuracy: 0.7516 - val_loss: 0.7245 - val_accuracy: 0.8750\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 205s 12s/step - loss: 0.3874 - accuracy: 0.8705 - val_loss: 0.8293 - val_accuracy: 0.6458\n",
            "\n",
            "wait mode, step: 1\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 220s 12s/step - loss: 0.2980 - accuracy: 0.7846 - val_loss: 0.8302 - val_accuracy: 0.5000\n",
            "\n",
            "wait mode, step: 2\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 215s 12s/step - loss: 0.2889 - accuracy: 0.8287 - val_loss: 1.4097 - val_accuracy: 0.8611\n",
            "\n",
            "wait mode, step: 3\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 213s 12s/step - loss: 0.3308 - accuracy: 0.9491 - val_loss: 0.4824 - val_accuracy: 0.8750\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 228s 13s/step - loss: 0.3415 - accuracy: 0.9384 - val_loss: 2.4972 - val_accuracy: 0.8958\n",
            "\n",
            "wait mode, step: 1\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 223s 13s/step - loss: 0.6558 - accuracy: 0.9203 - val_loss: 0.4408 - val_accuracy: 0.8958\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 229s 13s/step - loss: 0.2652 - accuracy: 0.9792 - val_loss: 2.3250 - val_accuracy: 0.6042\n",
            "\n",
            "wait mode, step: 1\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 220s 12s/step - loss: 0.8659 - accuracy: 0.6306 - val_loss: 1.4025 - val_accuracy: 0.5139\n",
            "\n",
            "wait mode, step: 2\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 219s 12s/step - loss: 0.5728 - accuracy: 0.4881 - val_loss: 0.6929 - val_accuracy: 0.5139\n",
            "\n",
            "wait mode, step: 3\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 216s 12s/step - loss: 0.6911 - accuracy: 0.5019 - val_loss: 0.6928 - val_accuracy: 0.5139\n",
            "\n",
            "wait mode, step: 4\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 221s 12s/step - loss: 0.6907 - accuracy: 0.5316 - val_loss: 0.6928 - val_accuracy: 0.5139\n",
            "\n",
            "wait mode, step: 5\n",
            "epoch: 11 : early stopping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk1l3F_88lhq"
      },
      "source": [
        "##fine tune "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7k4FSuL8lhr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f94197e-5780-45f8-d641-2357d0a39254"
      },
      "source": [
        "layers = base_model.layers\n",
        "for layer in layers[-50:-1]:\n",
        "  layer.trainable = True\n",
        "model_dense_fine=keras.models.Sequential()\n",
        "model_dense_fine.add(base_model)\n",
        "for i in range(1,len(model_dense.layers)):\n",
        "  model_dense_fine.add(model_dense.layers[i])\n",
        "model_dense_fine.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "model_dense_fine.fit(X_train,y_train,epochs=1000,validation_split=0.2,callbacks=[es_callback])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer ModuleWrapper has arguments in `__init__` and therefore must override `get_config`.\n",
            "Epoch 1/1000\n",
            "18/18 [==============================] - 224s 12s/step - loss: 0.2804 - accuracy: 0.9514 - val_loss: 0.3971 - val_accuracy: 0.8819\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 217s 12s/step - loss: 0.1125 - accuracy: 0.9601 - val_loss: 0.7936 - val_accuracy: 0.9028\n",
            "\n",
            "wait mode, step: 1\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 210s 12s/step - loss: 0.1595 - accuracy: 0.9670 - val_loss: 1.2882 - val_accuracy: 0.8889\n",
            "\n",
            "wait mode, step: 2\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 210s 12s/step - loss: 0.0668 - accuracy: 0.9792 - val_loss: 0.6676 - val_accuracy: 0.8889\n",
            "\n",
            "wait mode, step: 3\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 218s 12s/step - loss: 0.0482 - accuracy: 0.9878 - val_loss: 0.7413 - val_accuracy: 0.8819\n",
            "\n",
            "wait mode, step: 4\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 215s 12s/step - loss: 0.0474 - accuracy: 0.9844 - val_loss: 0.9795 - val_accuracy: 0.8819\n",
            "\n",
            "wait mode, step: 5\n",
            "epoch: 5 : early stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fea53b1dc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2ywWEFM8lhs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c1fccd7-8db2-4759-994f-842856e781e3"
      },
      "source": [
        "prediction_fine_tune_dense=np.argmax(model_dense_fine.predict(X_test),axis=1)\n",
        "print(\"DenseNet Result =====================>>>>\")\n",
        "print('accuracy without fine tuning = '+ str(accuracy_score(y_test,prediction_without_fine_tune_dense)))\n",
        "print('confusion matrix without fine tuning'+ str( confusion_matrix(y_test,prediction_without_fine_tune_dense)))\n",
        "print('accuracy with fine tuning = '+ str(accuracy_score(y_test,prediction_fine_tune_dense)))\n",
        "print('confusion matrix with fine tuning'+ str( confusion_matrix(y_test,prediction_fine_tune_dense)))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DenseNet Result =====================>>>>\n",
            "accuracy without fine tuning = 0.925\n",
            "confusion matrix without fine tuning[[39  2]\n",
            " [ 4 35]]\n",
            "accuracy with fine tuning = 0.9375\n",
            "confusion matrix with fine tuning[[37  4]\n",
            " [ 1 38]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}